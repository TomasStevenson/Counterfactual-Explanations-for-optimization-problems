{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec05512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GRB_LICENSE_FILE\"] = r\"C:\\Users\\PC2\\OneDrive\\Desktop\\gurobi.lic\"\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2719080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEST WCE FOUND ===\n",
      "L1 dist: 1.0\n",
      "delta b: [ 0 -1]\n",
      "new b: [ 4. -1.  0.]\n",
      "new A: [[ 1.  1.  0.  0.]\n",
      " [ 1.  0. -5.  0.]\n",
      " [ 0.  1.  0. -5.]]\n",
      "new c: [2. 1. 3. 1.]\n",
      "theta: 8.0\n",
      "witness obj: 8.0\n",
      "witness x: [0. 4. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Tuple, Optional, Dict, Any\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Data structures\n",
    "# =========================================================\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StandardFormMILP:\n",
    "    \"\"\"\n",
    "    Standard-form-ish MILP container.\n",
    "    We support mixed senses (>=, <=, =) and mixed variable types.\n",
    "    Objective: min c^T x\n",
    "    Constraints: A x (sense) b\n",
    "    \"\"\"\n",
    "    A: np.ndarray                 # shape (m,n)\n",
    "    b: np.ndarray                 # shape (m,)\n",
    "    sense: List[str]              # length m, each in {\">=\", \"<=\", \"=\"}\n",
    "    c: np.ndarray                 # shape (n,)\n",
    "    lb: np.ndarray                # shape (n,)\n",
    "    ub: np.ndarray                # shape (n,)\n",
    "    vtype: List[str]              # length n, each in {\"C\",\"I\",\"B\"}\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MutableSpec:\n",
    "    \"\"\"\n",
    "    Which parameters are mutable, and their integer delta bounds.\n",
    "\n",
    "    - b_idx: indices of RHS entries b_i that can change\n",
    "    - c_idx: indices of objective coefficients c_j that can change\n",
    "    - A_idx: list of (i,j) indices of A_ij coefficients that can change\n",
    "\n",
    "    Delta bounds are uniform here for simplicity; you can extend to per-index bounds.\n",
    "    \"\"\"\n",
    "    b_idx: List[int]\n",
    "    c_idx: List[int]\n",
    "    A_idx: List[Tuple[int,int]]\n",
    "    delta_lb: int   # integer lower bound for each delta component\n",
    "    delta_ub: int   # integer upper bound for each delta component\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Model builder (standard form -> Gurobi)\n",
    "# =========================================================\n",
    "\n",
    "def build_forward_model(data: StandardFormMILP,\n",
    "                        override: Optional[Dict[str, Any]] = None,\n",
    "                        output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Build a fresh Gurobi model from standard-form data.\n",
    "    override can contain updated A, b, c (numpy arrays).\n",
    "    Returns (model, x_vars, constrs, obj_expr).\n",
    "    \"\"\"\n",
    "    A = data.A if override is None or \"A\" not in override else override[\"A\"]\n",
    "    b = data.b if override is None or \"b\" not in override else override[\"b\"]\n",
    "    c = data.c if override is None or \"c\" not in override else override[\"c\"]\n",
    "\n",
    "    m, n = A.shape\n",
    "    model = gp.Model(\"forward\")\n",
    "    model.Params.OutputFlag = output_flag\n",
    "\n",
    "    # Variables\n",
    "    x = []\n",
    "    for j in range(n):\n",
    "        vt = data.vtype[j]\n",
    "        if vt not in (\"C\", \"I\", \"B\"):\n",
    "            raise ValueError(f\"Invalid vtype[{j}]={vt}. Use 'C','I','B'.\")\n",
    "        xj = model.addVar(lb=float(data.lb[j]), ub=float(data.ub[j]),\n",
    "                          vtype={\"C\":GRB.CONTINUOUS,\"I\":GRB.INTEGER,\"B\":GRB.BINARY}[vt],\n",
    "                          name=f\"x[{j}]\")\n",
    "        x.append(xj)\n",
    "\n",
    "    # Objective\n",
    "    obj = gp.quicksum(float(c[j]) * x[j] for j in range(n))\n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    constrs = []\n",
    "    for i in range(m):\n",
    "        lhs = gp.quicksum(float(A[i,j]) * x[j] for j in range(n))\n",
    "        s = data.sense[i]\n",
    "        if s == \">=\":\n",
    "            ci = model.addConstr(lhs >= float(b[i]), name=f\"con[{i}]\")\n",
    "        elif s == \"<=\":\n",
    "            ci = model.addConstr(lhs <= float(b[i]), name=f\"con[{i}]\")\n",
    "        elif s == \"=\":\n",
    "            ci = model.addConstr(lhs == float(b[i]), name=f\"con[{i}]\")\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid sense[{i}]={s}. Use '>=','<=','='.\")\n",
    "        constrs.append(ci)\n",
    "\n",
    "    model.optimize()\n",
    "    return model, x, constrs, obj\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Apply deltas to (A,b,c)\n",
    "# =========================================================\n",
    "\n",
    "def apply_deltas(base: StandardFormMILP,\n",
    "                 spec: MutableSpec,\n",
    "                 delta_b: np.ndarray,\n",
    "                 delta_c: np.ndarray,\n",
    "                 delta_A: np.ndarray):\n",
    "    \"\"\"\n",
    "    Produces new (A,b,c) = (A0+ΔA, b0+Δb, c0+Δc) based on spec ordering.\n",
    "    \"\"\"\n",
    "    A = base.A.copy()\n",
    "    b = base.b.copy()\n",
    "    c = base.c.copy()\n",
    "\n",
    "    for k, i in enumerate(spec.b_idx):\n",
    "        b[i] = b[i] + delta_b[k]\n",
    "    for k, j in enumerate(spec.c_idx):\n",
    "        c[j] = c[j] + delta_c[k]\n",
    "    for k, (i,j) in enumerate(spec.A_idx):\n",
    "        A[i,j] = A[i,j] + delta_A[k]\n",
    "\n",
    "    return A, b, c\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Witness check for WCE (existential / optimistic)\n",
    "# =========================================================\n",
    "\n",
    "def witness_exists(base: StandardFormMILP,\n",
    "                   A: np.ndarray, b: np.ndarray, c: np.ndarray,\n",
    "                   theta: float,\n",
    "                   desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                   tol: float = 1e-6,\n",
    "                   output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Returns (True, witness_solution_dict) if exists x in desired space that is LL-optimal:\n",
    "      feasible for (A,b), satisfies desired constraints, and objective <= theta+tol.\n",
    "    \"\"\"\n",
    "    model, x, constrs, obj = build_forward_model(\n",
    "        StandardFormMILP(A=A, b=b, sense=base.sense, c=c, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "        override=None,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "\n",
    "    # Add desired space constraints\n",
    "    desired_space_cb(model, x, constrs)\n",
    "\n",
    "    # Optimality cap\n",
    "    model.addConstr(obj <= theta + tol, name=\"optimality_cap\")\n",
    "\n",
    "    model.optimize()\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        sol = {\"obj\": model.ObjVal, \"x\": np.array([v.X for v in x])}\n",
    "        return True, sol\n",
    "    return False, None\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Master over delta variables with no-good cuts (enumerative CCG baseline)\n",
    "# =========================================================\n",
    "\n",
    "def build_master(spec: MutableSpec,\n",
    "                 output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Master decision variables are integer deltas for all mutable parameters.\n",
    "    Objective: L1 norm of all deltas.\n",
    "    Returns (model, delta_vars, abs_vars_plus_minus) for later no-good cuts.\n",
    "    \"\"\"\n",
    "    model = gp.Model(\"master\")\n",
    "    model.Params.OutputFlag = output_flag\n",
    "\n",
    "    # Delta variables\n",
    "    db = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"db[{k}]\")\n",
    "          for k in range(len(spec.b_idx))]\n",
    "    dc = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"dc[{k}]\")\n",
    "          for k in range(len(spec.c_idx))]\n",
    "    dA = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"dA[{k}]\")\n",
    "          for k in range(len(spec.A_idx))]\n",
    "\n",
    "    # L1 linearization: sum |delta|\n",
    "    def add_abs(v: gp.Var, name: str):\n",
    "        p = model.addVar(lb=0.0, name=f\"{name}_p\")\n",
    "        m = model.addVar(lb=0.0, name=f\"{name}_m\")\n",
    "        model.addConstr(v == p - m, name=f\"{name}_abs\")\n",
    "        return p + m\n",
    "\n",
    "    abs_terms = []\n",
    "    for k, v in enumerate(db):\n",
    "        abs_terms.append(add_abs(v, f\"abs_db[{k}]\"))\n",
    "    for k, v in enumerate(dc):\n",
    "        abs_terms.append(add_abs(v, f\"abs_dc[{k}]\"))\n",
    "    for k, v in enumerate(dA):\n",
    "        abs_terms.append(add_abs(v, f\"abs_dA[{k}]\"))\n",
    "\n",
    "    model.setObjective(gp.quicksum(abs_terms), GRB.MINIMIZE)\n",
    "    model.update()\n",
    "    return model, db, dc, dA\n",
    "\n",
    "\n",
    "def add_no_good_cut(model: gp.Model,\n",
    "                    vars_list: List[gp.Var],\n",
    "                    values: List[int],\n",
    "                    name: str):\n",
    "    \"\"\"\n",
    "    Correct no-good cut for bounded integer variables:\n",
    "    exclude exactly (vars_list == valuesvalues.\n",
    "\n",
    "    Enforces: exists k such that v_k <= val_k-1 OR v_k >= val_k+1.\n",
    "    Implemented via two indicator binaries per component.\n",
    "    \"\"\"\n",
    "    assert len(vars_list) == len(values)\n",
    "\n",
    "    if len(vars_list) == 0:\n",
    "        model.addConstr(0 >= 1, name=name)\n",
    "        return\n",
    "\n",
    "    diffs = []\n",
    "    for k, (v, val) in enumerate(zip(vars_list, values)):\n",
    "        u = model.addVar(vtype=GRB.BINARY, name=f\"{name}_u[{k}]\")  # v >= val+1\n",
    "        l = model.addVar(vtype=GRB.BINARY, name=f\"{name}_l[{k}]\")  # v <= val-1\n",
    "        model.addConstr(u + l <= 1, name=f\"{name}_one_side[{k}]\")\n",
    "\n",
    "        # If u=1 => v >= val+1\n",
    "        model.addGenConstrIndicator(u, True, v >= val + 1, name=f\"{name}_ge[{k}]\")\n",
    "        # If l=1 => v <= val-1\n",
    "        model.addGenConstrIndicator(l, True, v <= val - 1, name=f\"{name}_le[{k}]\")\n",
    "\n",
    "        diffs.append(u + l)\n",
    "\n",
    "    model.addConstr(gp.quicksum(diffs) >= 1, name=f\"{name}_exclude_point\")\n",
    "    model.update()\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# General WCE solver (enumerative CCG baseline)\n",
    "# =========================================================\n",
    "\n",
    "def solve_wce_general(base: StandardFormMILP,\n",
    "                      spec: MutableSpec,\n",
    "                      desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                      max_iter: int = 50,\n",
    "                      tol: float = 0.0,\n",
    "                      master_output: int = 0,\n",
    "                      oracle_output: int = 0):\n",
    "    \"\"\"\n",
    "    General WCE solver:\n",
    "      min ||ΔΩ||_1 s.t. exists optimal LL solution in desired space.\n",
    "\n",
    "    Returns dict with best solution found, or None if none found within bounds/iterations.\n",
    "    \"\"\"\n",
    "    master, db_vars, dc_vars, dA_vars = build_master(spec, output_flag=master_output)\n",
    "\n",
    "    UB = float(\"inf\")\n",
    "    best = None\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        master.optimize()\n",
    "        if master.Status != GRB.OPTIMAL:\n",
    "            break\n",
    "\n",
    "        # Read deltas\n",
    "        db_val = np.array([int(round(v.X)) for v in db_vars], dtype=int)\n",
    "        dc_val = np.array([int(round(v.X)) for v in dc_vars], dtype=int)\n",
    "        dA_val = np.array([int(round(v.X)) for v in dA_vars], dtype=int)\n",
    "        dist = master.ObjVal\n",
    "\n",
    "        # Apply deltas\n",
    "        A_new, b_new, c_new = apply_deltas(base, spec, db_val, dc_val, dA_val)\n",
    "\n",
    "        # Oracle: solve forward to get theta\n",
    "        fwd_model, x_vars, constrs, obj_expr = build_forward_model(\n",
    "            StandardFormMILP(A=A_new, b=b_new, sense=base.sense, c=c_new, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "            override=None,\n",
    "            output_flag=oracle_output\n",
    "        )\n",
    "        if fwd_model.Status != GRB.OPTIMAL:\n",
    "            # treat as failure; cut this delta vector\n",
    "            all_master_vars = db_vars + dc_vars + dA_vars\n",
    "            all_vals = list(db_val) + list(dc_val) + list(dA_val)\n",
    "            add_no_good_cut(master, all_master_vars, all_vals, name=f\"nogood_infeas[{it}]\")\n",
    "            continue\n",
    "\n",
    "        theta = fwd_model.ObjVal\n",
    "\n",
    "        # Witness check\n",
    "        ok, witness = witness_exists(base, A_new, b_new, c_new, theta, desired_space_cb,\n",
    "                                     tol=1e-6, output_flag=oracle_output)\n",
    "\n",
    "        if ok:\n",
    "            if dist < UB:\n",
    "                UB = dist\n",
    "                best = {\n",
    "                    \"dist\": UB,\n",
    "                    \"db\": db_val, \"dc\": dc_val, \"dA\": dA_val,\n",
    "                    \"A\": A_new, \"b\": b_new, \"c\": c_new,\n",
    "                    \"theta\": theta,\n",
    "                    \"witness\": witness,\n",
    "                }\n",
    "            # Since master is minimizing dist, if we found a witness at current optimum dist,\n",
    "            # we are done (LB==UB) for this enumerative master.\n",
    "            if UB - dist <= tol:\n",
    "                break\n",
    "\n",
    "        # If witness fails, exclude this delta vector\n",
    "        all_master_vars = db_vars + dc_vars + dA_vars\n",
    "        all_vals = list(db_val) + list(dc_val) + list(dA_val)\n",
    "        add_no_good_cut(master, all_master_vars, all_vals, name=f\"nogood[{it}]\")\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Demo on your toy (now in standard form)\n",
    "# =========================================================\n",
    "\n",
    "def demo():\n",
    "    # Toy variables: x1,x2 continuous, y1,y2 binary\n",
    "    # Put them into x vector as [x1,x2,y1,y2]\n",
    "    # Objective: 2x1 + 1x2 + 3y1 + 1y2\n",
    "    c0 = np.array([2, 1, 3, 1], dtype=float)\n",
    "\n",
    "    # Constraints:\n",
    "    # (1) x1 + x2 >= b\n",
    "    # (2) x1 - 5 y1 <= 0\n",
    "    # (3) x2 - 5 y2 <= 0\n",
    "    # Standard form with mixed senses:\n",
    "    A0 = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, -5, 0],\n",
    "        [0, 1, 0, -5],\n",
    "    ], dtype=float)\n",
    "    sense = [\">=\", \"<=\", \"<=\"]\n",
    "\n",
    "    b0 = np.array([4, 0, 0], dtype=float)\n",
    "\n",
    "    lb = np.array([0, 0, 0, 0], dtype=float)\n",
    "    ub = np.array([GRB.INFINITY, GRB.INFINITY, 1, 1], dtype=float)\n",
    "    vtype = [\"C\", \"C\", \"B\", \"B\"]\n",
    "\n",
    "    base = StandardFormMILP(A=A0, b=b0, sense=sense, c=c0, lb=lb, ub=ub, vtype=vtype)\n",
    "\n",
    "    # Desired space: y1 == 1  (x[2] is y1)\n",
    "    def desired_cb(model: gp.Model, xvars: List[gp.Var], constrs: List[gp.Constr]):\n",
    "        model.addConstr(xvars[2] == 1, name=\"desired_y1_on\")\n",
    "        model.addConstr(xvars[0] <= 1.5, name=\"desired_x2_limit\")\n",
    "\n",
    "    # Mutable spec: allow changing ONLY the RHS of constraint (1) (b[0]) by integer deltas\n",
    "    spec = MutableSpec(\n",
    "        b_idx=[0,1],     # only demand RHS mutable\n",
    "        c_idx=[],      # no cost changes\n",
    "        A_idx=[],      # no A changes\n",
    "        delta_lb=-10,\n",
    "        delta_ub=+10\n",
    "    )\n",
    "\n",
    "    best = solve_wce_general(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        max_iter=50,\n",
    "        master_output=0,\n",
    "        oracle_output=0\n",
    "    )\n",
    "\n",
    "    if best is None:\n",
    "        print(\"No WCE found.\")\n",
    "        return\n",
    "\n",
    "    print(\"=== BEST WCE FOUND ===\")\n",
    "    print(\"L1 dist:\", best[\"dist\"])\n",
    "    print(\"delta b:\", best[\"db\"])\n",
    "    print(\"new b:\", best[\"b\"])\n",
    "    print(\"new A:\", best[\"A\"])\n",
    "    print(\"new c:\", best[\"c\"])\n",
    "    print(\"theta:\", best[\"theta\"])\n",
    "    print(\"witness obj:\", best[\"witness\"][\"obj\"])\n",
    "    print(\"witness x:\", best[\"witness\"][\"x\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8c3f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_forward_only(base: StandardFormMILP, A: np.ndarray, b: np.ndarray, c: np.ndarray, output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Solve the forward MILP once and return theta and primal x.\n",
    "    \"\"\"\n",
    "    fwd_model, x_vars, constrs, obj_expr = build_forward_model(\n",
    "        StandardFormMILP(A=A, b=b, sense=base.sense, c=c, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "        override=None,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "    if fwd_model.Status != GRB.OPTIMAL:\n",
    "        return None, None\n",
    "    x = np.array([v.X for v in x_vars])\n",
    "    return fwd_model.ObjVal, x\n",
    "\n",
    "\n",
    "def compute_l1_dist_from_deltas(db: np.ndarray, dc: np.ndarray, dA: np.ndarray):\n",
    "    return float(np.sum(np.abs(db)) + np.sum(np.abs(dc)) + np.sum(np.abs(dA)))\n",
    "\n",
    "\n",
    "def sanity_check_wce_result(base: StandardFormMILP,\n",
    "                            spec: MutableSpec,\n",
    "                            desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                            best: Dict[str, Any],\n",
    "                            tol: float = 1e-6,\n",
    "                            output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Sanity-check that 'best' is a valid WCE for the forward model:\n",
    "      1) best['dist'] matches |deltas|_1\n",
    "      2) theta is the forward optimum under (A,b,c)\n",
    "      3) witness exists in desired space with obj <= theta + tol\n",
    "      4) witness objective approximately equals theta (optional check)\n",
    "    \"\"\"\n",
    "    assert best is not None, \"best is None (no WCE found).\"\n",
    "\n",
    "    # 1) Check distance\n",
    "    dist_calc = compute_l1_dist_from_deltas(best[\"db\"], best[\"dc\"], best[\"dA\"])\n",
    "    print(\"=== SANITY 1: Distance ===\")\n",
    "    print(f\"reported dist = {best['dist']}, computed dist = {dist_calc}\")\n",
    "    if abs(best[\"dist\"] - dist_calc) > 1e-6:\n",
    "        print(\"WARNING: dist mismatch. (If master used weighted distance, this is expected.)\")\n",
    "\n",
    "    # 2) Re-solve forward\n",
    "    print(\"\\n=== SANITY 2: Forward optimality ===\")\n",
    "    theta_star, x_star = solve_forward_only(base, best[\"A\"], best[\"b\"], best[\"c\"], output_flag=output_flag)\n",
    "    if theta_star is None:\n",
    "        raise RuntimeError(\"Forward model at best parameters is not optimal/feasible.\")\n",
    "    print(f\"theta(recomputed) = {theta_star:.6f} | theta(stored) = {best['theta']:.6f} | gap = {best['theta'] - theta_star:.3e}\")\n",
    "\n",
    "    # 3) Witness existence\n",
    "    print(\"\\n=== SANITY 3: Witness exists in desired space at optimum ===\")\n",
    "    ok, wit = witness_exists(\n",
    "        base=base,\n",
    "        A=best[\"A\"],\n",
    "        b=best[\"b\"],\n",
    "        c=best[\"c\"],\n",
    "        theta=theta_star,\n",
    "        desired_space_cb=desired_space_cb,\n",
    "        tol=tol,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "    print(\"witness_exists ?\", ok)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"Sanity failed: no witness exists, so this is NOT a WCE.\")\n",
    "\n",
    "    print(f\"witness obj = {wit['obj']:.6f} | theta = {theta_star:.6f} | wit-theta = {wit['obj'] - theta_star:.3e}\")\n",
    "\n",
    "    # 4) Optional: check witness objective approximately equals theta (it should, given your formulation)\n",
    "    if wit[\"obj\"] > theta_star + 1e-5:\n",
    "        print(\"WARNING: witness objective is above theta; check your witness constraint/tolerance.\")\n",
    "\n",
    "    print(\"\\n=== SANITY PASSED: This is a valid Weak Optimality CE ===\")\n",
    "    return {\"theta\": theta_star, \"x_opt\": x_star, \"witness\": wit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f54302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEST WCE FOUND ===\n",
      "L1 dist: 2.0\n",
      "delta b: [2]\n",
      "new b: [6. 0. 0.]\n",
      "theta: 11.0\n",
      "witness obj: 11.0\n",
      "witness x: [1. 5. 1. 1.]\n",
      "\n",
      "=== RUN SANITY CHECK ===\n",
      "=== SANITY 1: Distance ===\n",
      "reported dist = 2.0, computed dist = 2.0\n",
      "\n",
      "=== SANITY 2: Forward optimality ===\n",
      "theta(recomputed) = 11.000000 | theta(stored) = 11.000000 | gap = 0.000e+00\n",
      "\n",
      "=== SANITY 3: Witness exists in desired space at optimum ===\n",
      "witness_exists ? True\n",
      "witness obj = 11.000000 | theta = 11.000000 | wit-theta = 0.000e+00\n",
      "\n",
      "=== SANITY PASSED: This is a valid Weak Optimality CE ===\n"
     ]
    }
   ],
   "source": [
    "def demo():\n",
    "    # -------------------------------\n",
    "    # 1) Define the base MILP\n",
    "    # -------------------------------\n",
    "    c0 = np.array([2, 1, 3, 1], dtype=float)\n",
    "\n",
    "    A0 = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, -5, 0],\n",
    "        [0, 1, 0, -5],\n",
    "    ], dtype=float)\n",
    "\n",
    "    sense = [\">=\", \"<=\", \"<=\"]\n",
    "    b0 = np.array([4, 0, 0], dtype=float)\n",
    "\n",
    "    lb = np.array([0, 0, 0, 0], dtype=float)\n",
    "    ub = np.array([GRB.INFINITY, GRB.INFINITY, 1, 1], dtype=float)\n",
    "    vtype = [\"C\", \"C\", \"B\", \"B\"]\n",
    "\n",
    "    base = StandardFormMILP(\n",
    "        A=A0, b=b0, sense=sense,\n",
    "        c=c0, lb=lb, ub=ub, vtype=vtype\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) Desired space\n",
    "    # -------------------------------\n",
    "    def desired_cb(model, xvars, constrs):\n",
    "        # y1 == 1  (x[2])\n",
    "        model.addConstr(xvars[2] == 1, name=\"desired_y1_on\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) Mutable specification\n",
    "    # -------------------------------\n",
    "    spec = MutableSpec(\n",
    "        b_idx=[0],     # only demand RHS\n",
    "        c_idx=[],\n",
    "        A_idx=[],\n",
    "        delta_lb=-10,\n",
    "        delta_ub=10\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4) Solve WCE\n",
    "    # -------------------------------\n",
    "    best = solve_wce_general(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        max_iter=50,\n",
    "        master_output=0,\n",
    "        oracle_output=0\n",
    "    )\n",
    "\n",
    "    if best is None:\n",
    "        print(\"No WCE found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== BEST WCE FOUND ===\")\n",
    "    print(\"L1 dist:\", best[\"dist\"])\n",
    "    print(\"delta b:\", best[\"db\"])\n",
    "    print(\"new b:\", best[\"b\"])\n",
    "    print(\"theta:\", best[\"theta\"])\n",
    "    print(\"witness obj:\", best[\"witness\"][\"obj\"])\n",
    "    print(\"witness x:\", best[\"witness\"][\"x\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5) Sanity check\n",
    "    # -------------------------------\n",
    "    print(\"\\n=== RUN SANITY CHECK ===\")\n",
    "    sanity_check_wce_result(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        best=best,\n",
    "        tol=1e-6,\n",
    "        output_flag=0\n",
    "    )\n",
    "\n",
    "\n",
    "# ✅ ONLY THIS at top level\n",
    "demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CEexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
