{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec05512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GRB_LICENSE_FILE\"] = r\"C:\\Users\\tomas\\Desktop\\gurobi.lic\"\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2719080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2653481\n",
      "Academic license 2653481 - for non-commercial use only - registered to to___@ug.uchile.cl\n",
      "=== BEST WCE FOUND ===\n",
      "L1 dist: 1.0\n",
      "delta b: [ 0 -1]\n",
      "new b: [ 4. -1.  0.]\n",
      "new A: [[ 1.  1.  0.  0.]\n",
      " [ 1.  0. -5.  0.]\n",
      " [ 0.  1.  0. -5.]]\n",
      "new c: [2. 1. 3. 1.]\n",
      "theta: 8.0\n",
      "witness obj: 8.0\n",
      "witness x: [0. 4. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Tuple, Optional, Dict, Any\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Data structures\n",
    "# =========================================================\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StandardFormMILP:\n",
    "    \"\"\"\n",
    "    Standard-form-ish MILP container.\n",
    "    We support mixed senses (>=, <=, =) and mixed variable types.\n",
    "    Objective: min c^T x\n",
    "    Constraints: A x (sense) b\n",
    "    \"\"\"\n",
    "    A: np.ndarray                 # shape (m,n)\n",
    "    b: np.ndarray                 # shape (m,)\n",
    "    sense: List[str]              # length m, each in {\">=\", \"<=\", \"=\"}\n",
    "    c: np.ndarray                 # shape (n,)\n",
    "    lb: np.ndarray                # shape (n,)\n",
    "    ub: np.ndarray                # shape (n,)\n",
    "    vtype: List[str]              # length n, each in {\"C\",\"I\",\"B\"}\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MutableSpec:\n",
    "    \"\"\"\n",
    "    Which parameters are mutable, and their integer delta bounds.\n",
    "\n",
    "    - b_idx: indices of RHS entries b_i that can change\n",
    "    - c_idx: indices of objective coefficients c_j that can change\n",
    "    - A_idx: list of (i,j) indices of A_ij coefficients that can change\n",
    "\n",
    "    Delta bounds are uniform here for simplicity; you can extend to per-index bounds.\n",
    "    \"\"\"\n",
    "    b_idx: List[int]\n",
    "    c_idx: List[int]\n",
    "    A_idx: List[Tuple[int,int]]\n",
    "    delta_lb: int   # integer lower bound for each delta component\n",
    "    delta_ub: int   # integer upper bound for each delta component\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Model builder (standard form -> Gurobi)\n",
    "# =========================================================\n",
    "\n",
    "def build_forward_model(data: StandardFormMILP,\n",
    "                        override: Optional[Dict[str, Any]] = None,\n",
    "                        output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Build a fresh Gurobi model from standard-form data.\n",
    "    override can contain updated A, b, c (numpy arrays).\n",
    "    Returns (model, x_vars, constrs, obj_expr).\n",
    "    \"\"\"\n",
    "    A = data.A if override is None or \"A\" not in override else override[\"A\"]\n",
    "    b = data.b if override is None or \"b\" not in override else override[\"b\"]\n",
    "    c = data.c if override is None or \"c\" not in override else override[\"c\"]\n",
    "\n",
    "    m, n = A.shape\n",
    "    model = gp.Model(\"forward\")\n",
    "    model.Params.OutputFlag = output_flag\n",
    "\n",
    "    # Variables\n",
    "    x = []\n",
    "    for j in range(n):\n",
    "        vt = data.vtype[j]\n",
    "        if vt not in (\"C\", \"I\", \"B\"):\n",
    "            raise ValueError(f\"Invalid vtype[{j}]={vt}. Use 'C','I','B'.\")\n",
    "        xj = model.addVar(lb=float(data.lb[j]), ub=float(data.ub[j]),\n",
    "                          vtype={\"C\":GRB.CONTINUOUS,\"I\":GRB.INTEGER,\"B\":GRB.BINARY}[vt],\n",
    "                          name=f\"x[{j}]\")\n",
    "        x.append(xj)\n",
    "\n",
    "    # Objective\n",
    "    obj = gp.quicksum(float(c[j]) * x[j] for j in range(n))\n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    constrs = []\n",
    "    for i in range(m):\n",
    "        lhs = gp.quicksum(float(A[i,j]) * x[j] for j in range(n))\n",
    "        s = data.sense[i]\n",
    "        if s == \">=\":\n",
    "            ci = model.addConstr(lhs >= float(b[i]), name=f\"con[{i}]\")\n",
    "        elif s == \"<=\":\n",
    "            ci = model.addConstr(lhs <= float(b[i]), name=f\"con[{i}]\")\n",
    "        elif s == \"=\":\n",
    "            ci = model.addConstr(lhs == float(b[i]), name=f\"con[{i}]\")\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid sense[{i}]={s}. Use '>=','<=','='.\")\n",
    "        constrs.append(ci)\n",
    "\n",
    "    model.optimize()\n",
    "    return model, x, constrs, obj\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Apply deltas to (A,b,c)\n",
    "# =========================================================\n",
    "\n",
    "def apply_deltas(base: StandardFormMILP,\n",
    "                 spec: MutableSpec,\n",
    "                 delta_b: np.ndarray,\n",
    "                 delta_c: np.ndarray,\n",
    "                 delta_A: np.ndarray):\n",
    "    \"\"\"\n",
    "    Produces new (A,b,c) = (A0+ΔA, b0+Δb, c0+Δc) based on spec ordering.\n",
    "    \"\"\"\n",
    "    A = base.A.copy()\n",
    "    b = base.b.copy()\n",
    "    c = base.c.copy()\n",
    "\n",
    "    for k, i in enumerate(spec.b_idx):\n",
    "        b[i] = b[i] + delta_b[k]\n",
    "    for k, j in enumerate(spec.c_idx):\n",
    "        c[j] = c[j] + delta_c[k]\n",
    "    for k, (i,j) in enumerate(spec.A_idx):\n",
    "        A[i,j] = A[i,j] + delta_A[k]\n",
    "\n",
    "    return A, b, c\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Witness check for WCE (existential / optimistic)\n",
    "# =========================================================\n",
    "\n",
    "def witness_exists(base: StandardFormMILP,\n",
    "                   A: np.ndarray, b: np.ndarray, c: np.ndarray,\n",
    "                   theta: float,\n",
    "                   desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                   tol: float = 1e-6,\n",
    "                   output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Returns (True, witness_solution_dict) if exists x in desired space that is LL-optimal:\n",
    "      feasible for (A,b), satisfies desired constraints, and objective <= theta+tol.\n",
    "    \"\"\"\n",
    "    model, x, constrs, obj = build_forward_model(\n",
    "        StandardFormMILP(A=A, b=b, sense=base.sense, c=c, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "        override=None,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "\n",
    "    # Add desired space constraints\n",
    "    desired_space_cb(model, x, constrs)\n",
    "\n",
    "    # Optimality cap\n",
    "    model.addConstr(obj <= theta + tol, name=\"optimality_cap\")\n",
    "\n",
    "    model.optimize()\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        sol = {\"obj\": model.ObjVal, \"x\": np.array([v.X for v in x])}\n",
    "        return True, sol\n",
    "    return False, None\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Master over delta variables with no-good cuts (enumerative CCG baseline)\n",
    "# =========================================================\n",
    "\n",
    "def build_master(spec: MutableSpec,\n",
    "                 output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Master decision variables are integer deltas for all mutable parameters.\n",
    "    Objective: L1 norm of all deltas.\n",
    "    Returns (model, delta_vars, abs_vars_plus_minus) for later no-good cuts.\n",
    "    \"\"\"\n",
    "    model = gp.Model(\"master\")\n",
    "    model.Params.OutputFlag = output_flag\n",
    "\n",
    "    # Delta variables\n",
    "    db = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"db[{k}]\")\n",
    "          for k in range(len(spec.b_idx))]\n",
    "    dc = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"dc[{k}]\")\n",
    "          for k in range(len(spec.c_idx))]\n",
    "    dA = [model.addVar(vtype=GRB.INTEGER, lb=spec.delta_lb, ub=spec.delta_ub, name=f\"dA[{k}]\")\n",
    "          for k in range(len(spec.A_idx))]\n",
    "\n",
    "    # L1 linearization: sum |delta|\n",
    "    def add_abs(v: gp.Var, name: str):\n",
    "        p = model.addVar(lb=0.0, name=f\"{name}_p\")\n",
    "        m = model.addVar(lb=0.0, name=f\"{name}_m\")\n",
    "        model.addConstr(v == p - m, name=f\"{name}_abs\")\n",
    "        return p + m\n",
    "\n",
    "    abs_terms = []\n",
    "    for k, v in enumerate(db):\n",
    "        abs_terms.append(add_abs(v, f\"abs_db[{k}]\"))\n",
    "    for k, v in enumerate(dc):\n",
    "        abs_terms.append(add_abs(v, f\"abs_dc[{k}]\"))\n",
    "    for k, v in enumerate(dA):\n",
    "        abs_terms.append(add_abs(v, f\"abs_dA[{k}]\"))\n",
    "\n",
    "    model.setObjective(gp.quicksum(abs_terms), GRB.MINIMIZE)\n",
    "    model.update()\n",
    "    return model, db, dc, dA\n",
    "\n",
    "\n",
    "def add_no_good_cut(model: gp.Model,\n",
    "                    vars_list: List[gp.Var],\n",
    "                    values: List[int],\n",
    "                    name: str):\n",
    "    \"\"\"\n",
    "    Correct no-good cut for bounded integer variables:\n",
    "    exclude exactly (vars_list == valuesvalues.\n",
    "\n",
    "    Enforces: exists k such that v_k <= val_k-1 OR v_k >= val_k+1.\n",
    "    Implemented via two indicator binaries per component.\n",
    "    \"\"\"\n",
    "    assert len(vars_list) == len(values)\n",
    "\n",
    "    if len(vars_list) == 0:\n",
    "        model.addConstr(0 >= 1, name=name)\n",
    "        return\n",
    "\n",
    "    diffs = []\n",
    "    for k, (v, val) in enumerate(zip(vars_list, values)):\n",
    "        u = model.addVar(vtype=GRB.BINARY, name=f\"{name}_u[{k}]\")  # v >= val+1\n",
    "        l = model.addVar(vtype=GRB.BINARY, name=f\"{name}_l[{k}]\")  # v <= val-1\n",
    "        model.addConstr(u + l <= 1, name=f\"{name}_one_side[{k}]\")\n",
    "\n",
    "        # If u=1 => v >= val+1\n",
    "        model.addGenConstrIndicator(u, True, v >= val + 1, name=f\"{name}_ge[{k}]\")\n",
    "        # If l=1 => v <= val-1\n",
    "        model.addGenConstrIndicator(l, True, v <= val - 1, name=f\"{name}_le[{k}]\")\n",
    "\n",
    "        diffs.append(u + l)\n",
    "\n",
    "    model.addConstr(gp.quicksum(diffs) >= 1, name=f\"{name}_exclude_point\")\n",
    "    model.update()\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# General WCE solver (enumerative CCG baseline)\n",
    "# =========================================================\n",
    "\n",
    "def solve_wce_general(base: StandardFormMILP,\n",
    "                      spec: MutableSpec,\n",
    "                      desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                      max_iter: int = 50,\n",
    "                      tol: float = 0.0,\n",
    "                      master_output: int = 0,\n",
    "                      oracle_output: int = 0):\n",
    "    \"\"\"\n",
    "    General WCE solver:\n",
    "      min ||ΔΩ||_1 s.t. exists optimal LL solution in desired space.\n",
    "\n",
    "    Returns dict with best solution found, or None if none found within bounds/iterations.\n",
    "    \"\"\"\n",
    "    master, db_vars, dc_vars, dA_vars = build_master(spec, output_flag=master_output)\n",
    "\n",
    "    UB = float(\"inf\")\n",
    "    best = None\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        master.optimize()\n",
    "        if master.Status != GRB.OPTIMAL:\n",
    "            break\n",
    "\n",
    "        # Read deltas\n",
    "        db_val = np.array([int(round(v.X)) for v in db_vars], dtype=int)\n",
    "        dc_val = np.array([int(round(v.X)) for v in dc_vars], dtype=int)\n",
    "        dA_val = np.array([int(round(v.X)) for v in dA_vars], dtype=int)\n",
    "        dist = master.ObjVal\n",
    "\n",
    "        # Apply deltas\n",
    "        A_new, b_new, c_new = apply_deltas(base, spec, db_val, dc_val, dA_val)\n",
    "\n",
    "        # Oracle: solve forward to get theta\n",
    "        fwd_model, x_vars, constrs, obj_expr = build_forward_model(\n",
    "            StandardFormMILP(A=A_new, b=b_new, sense=base.sense, c=c_new, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "            override=None,\n",
    "            output_flag=oracle_output\n",
    "        )\n",
    "        if fwd_model.Status != GRB.OPTIMAL:\n",
    "            # treat as failure; cut this delta vector\n",
    "            all_master_vars = db_vars + dc_vars + dA_vars\n",
    "            all_vals = list(db_val) + list(dc_val) + list(dA_val)\n",
    "            add_no_good_cut(master, all_master_vars, all_vals, name=f\"nogood_infeas[{it}]\")\n",
    "            continue\n",
    "\n",
    "        theta = fwd_model.ObjVal\n",
    "\n",
    "        # Witness check\n",
    "        ok, witness = witness_exists(base, A_new, b_new, c_new, theta, desired_space_cb,\n",
    "                                     tol=1e-6, output_flag=oracle_output)\n",
    "\n",
    "        if ok:\n",
    "            if dist < UB:\n",
    "                UB = dist\n",
    "                best = {\n",
    "                    \"dist\": UB,\n",
    "                    \"db\": db_val, \"dc\": dc_val, \"dA\": dA_val,\n",
    "                    \"A\": A_new, \"b\": b_new, \"c\": c_new,\n",
    "                    \"theta\": theta,\n",
    "                    \"witness\": witness,\n",
    "                }\n",
    "            # Since master is minimizing dist, if we found a witness at current optimum dist,\n",
    "            # we are done (LB==UB) for this enumerative master.\n",
    "            if UB - dist <= tol:\n",
    "                break\n",
    "\n",
    "        # If witness fails, exclude this delta vector\n",
    "        all_master_vars = db_vars + dc_vars + dA_vars\n",
    "        all_vals = list(db_val) + list(dc_val) + list(dA_val)\n",
    "        add_no_good_cut(master, all_master_vars, all_vals, name=f\"nogood[{it}]\")\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Demo on your toy (now in standard form)\n",
    "# =========================================================\n",
    "\n",
    "def demo():\n",
    "    # Toy variables: x1,x2 continuous, y1,y2 binary\n",
    "    # Put them into x vector as [x1,x2,y1,y2]\n",
    "    # Objective: 2x1 + 1x2 + 3y1 + 1y2\n",
    "    c0 = np.array([2, 1, 3, 1], dtype=float)\n",
    "\n",
    "    # Constraints:\n",
    "    # (1) x1 + x2 >= b\n",
    "    # (2) x1 - 5 y1 <= 0\n",
    "    # (3) x2 - 5 y2 <= 0\n",
    "    # Standard form with mixed senses:\n",
    "    A0 = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, -5, 0],\n",
    "        [0, 1, 0, -5],\n",
    "    ], dtype=float)\n",
    "    sense = [\">=\", \"<=\", \"<=\"]\n",
    "\n",
    "    b0 = np.array([4, 0, 0], dtype=float)\n",
    "\n",
    "    lb = np.array([0, 0, 0, 0], dtype=float)\n",
    "    ub = np.array([GRB.INFINITY, GRB.INFINITY, 1, 1], dtype=float)\n",
    "    vtype = [\"C\", \"C\", \"B\", \"B\"]\n",
    "\n",
    "    base = StandardFormMILP(A=A0, b=b0, sense=sense, c=c0, lb=lb, ub=ub, vtype=vtype)\n",
    "\n",
    "    # Desired space: y1 == 1  (x[2] is y1)\n",
    "    def desired_cb(model: gp.Model, xvars: List[gp.Var], constrs: List[gp.Constr]):\n",
    "        model.addConstr(xvars[2] == 1, name=\"desired_y1_on\")\n",
    "        model.addConstr(xvars[0] <= 1.5, name=\"desired_x2_limit\")\n",
    "\n",
    "    # Mutable spec: allow changing ONLY the RHS of constraint (1) (b[0]) by integer deltas\n",
    "    spec = MutableSpec(\n",
    "        b_idx=[0,1],     # only demand RHS mutable\n",
    "        c_idx=[],      # no cost changes\n",
    "        A_idx=[],      # no A changes\n",
    "        delta_lb=-10,\n",
    "        delta_ub=+10\n",
    "    )\n",
    "\n",
    "    best = solve_wce_general(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        max_iter=50,\n",
    "        master_output=0,\n",
    "        oracle_output=0\n",
    "    )\n",
    "\n",
    "    if best is None:\n",
    "        print(\"No WCE found.\")\n",
    "        return\n",
    "\n",
    "    print(\"=== BEST WCE FOUND ===\")\n",
    "    print(\"L1 dist:\", best[\"dist\"])\n",
    "    print(\"delta b:\", best[\"db\"])\n",
    "    print(\"new b:\", best[\"b\"])\n",
    "    print(\"new A:\", best[\"A\"])\n",
    "    print(\"new c:\", best[\"c\"])\n",
    "    print(\"theta:\", best[\"theta\"])\n",
    "    print(\"witness obj:\", best[\"witness\"][\"obj\"])\n",
    "    print(\"witness x:\", best[\"witness\"][\"x\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_forward_only(base: StandardFormMILP, A: np.ndarray, b: np.ndarray, c: np.ndarray, output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Solve the forward MILP once and return theta and primal x.\n",
    "    \"\"\"\n",
    "    fwd_model, x_vars, constrs, obj_expr = build_forward_model(\n",
    "        StandardFormMILP(A=A, b=b, sense=base.sense, c=c, lb=base.lb, ub=base.ub, vtype=base.vtype),\n",
    "        override=None,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "    if fwd_model.Status != GRB.OPTIMAL:\n",
    "        return None, None\n",
    "    x = np.array([v.X for v in x_vars])\n",
    "    return fwd_model.ObjVal, x\n",
    "\n",
    "\n",
    "def compute_l1_dist_from_deltas(db: np.ndarray, dc: np.ndarray, dA: np.ndarray):\n",
    "    return float(np.sum(np.abs(db)) + np.sum(np.abs(dc)) + np.sum(np.abs(dA)))\n",
    "\n",
    "\n",
    "def sanity_check_wce_result(base: StandardFormMILP,\n",
    "                            spec: MutableSpec,\n",
    "                            desired_space_cb: Callable[[gp.Model, List[gp.Var], List[gp.Constr]], None],\n",
    "                            best: Dict[str, Any],\n",
    "                            tol: float = 1e-6,\n",
    "                            output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Sanity-check that 'best' is a valid WCE for the forward model:\n",
    "      1) best['dist'] matches |deltas|_1\n",
    "      2) theta is the forward optimum under (A,b,c)\n",
    "      3) witness exists in desired space with obj <= theta + tol\n",
    "      4) witness objective approximately equals theta (optional check)\n",
    "    \"\"\"\n",
    "    assert best is not None, \"best is None (no WCE found).\"\n",
    "\n",
    "    # 1) Check distance\n",
    "    dist_calc = compute_l1_dist_from_deltas(best[\"db\"], best[\"dc\"], best[\"dA\"])\n",
    "    print(\"=== SANITY 1: Distance ===\")\n",
    "    print(f\"reported dist = {best['dist']}, computed dist = {dist_calc}\")\n",
    "    if abs(best[\"dist\"] - dist_calc) > 1e-6:\n",
    "        print(\"WARNING: dist mismatch. (If master used weighted distance, this is expected.)\")\n",
    "\n",
    "    # 2) Re-solve forward\n",
    "    print(\"\\n=== SANITY 2: Forward optimality ===\")\n",
    "    theta_star, x_star = solve_forward_only(base, best[\"A\"], best[\"b\"], best[\"c\"], output_flag=output_flag)\n",
    "    if theta_star is None:\n",
    "        raise RuntimeError(\"Forward model at best parameters is not optimal/feasible.\")\n",
    "    print(f\"theta(recomputed) = {theta_star:.6f} | theta(stored) = {best['theta']:.6f} | gap = {best['theta'] - theta_star:.3e}\")\n",
    "\n",
    "    # 3) Witness existence\n",
    "    print(\"\\n=== SANITY 3: Witness exists in desired space at optimum ===\")\n",
    "    ok, wit = witness_exists(\n",
    "        base=base,\n",
    "        A=best[\"A\"],\n",
    "        b=best[\"b\"],\n",
    "        c=best[\"c\"],\n",
    "        theta=theta_star,\n",
    "        desired_space_cb=desired_space_cb,\n",
    "        tol=tol,\n",
    "        output_flag=output_flag\n",
    "    )\n",
    "    print(\"witness_exists ?\", ok)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"Sanity failed: no witness exists, so this is NOT a WCE.\")\n",
    "\n",
    "    print(f\"witness obj = {wit['obj']:.6f} | theta = {theta_star:.6f} | wit-theta = {wit['obj'] - theta_star:.3e}\")\n",
    "\n",
    "    # 4) Optional: check witness objective approximately equals theta (it should, given your formulation)\n",
    "    if wit[\"obj\"] > theta_star + 1e-5:\n",
    "        print(\"WARNING: witness objective is above theta; check your witness constraint/tolerance.\")\n",
    "\n",
    "    print(\"\\n=== SANITY PASSED: This is a valid Weak Optimality CE ===\")\n",
    "    return {\"theta\": theta_star, \"x_opt\": x_star, \"witness\": wit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f54302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo():\n",
    "    # -------------------------------\n",
    "    # 1) Define the base MILP\n",
    "    # -------------------------------\n",
    "    c0 = np.array([2, 1, 3, 1], dtype=float)\n",
    "\n",
    "    A0 = np.array([\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 0, -5, 0],\n",
    "        [0, 1, 0, -5],\n",
    "    ], dtype=float)\n",
    "\n",
    "    sense = [\">=\", \"<=\", \"<=\"]\n",
    "    b0 = np.array([4, 0, 0], dtype=float)\n",
    "\n",
    "    lb = np.array([0, 0, 0, 0], dtype=float)\n",
    "    ub = np.array([GRB.INFINITY, GRB.INFINITY, 1, 1], dtype=float)\n",
    "    vtype = [\"C\", \"C\", \"B\", \"B\"]\n",
    "\n",
    "    base = StandardFormMILP(\n",
    "        A=A0, b=b0, sense=sense,\n",
    "        c=c0, lb=lb, ub=ub, vtype=vtype\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) Desired space\n",
    "    # -------------------------------\n",
    "    def desired_cb(model, xvars, constrs):\n",
    "        # y1 == 1  (x[2])\n",
    "        model.addConstr(xvars[2] == 1, name=\"desired_y1_on\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) Mutable specification\n",
    "    # -------------------------------\n",
    "    spec = MutableSpec(\n",
    "        b_idx=[0],     # only demand RHS\n",
    "        c_idx=[],\n",
    "        A_idx=[],\n",
    "        delta_lb=-10,\n",
    "        delta_ub=10\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4) Solve WCE\n",
    "    # -------------------------------\n",
    "    best = solve_wce_general(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        max_iter=50,\n",
    "        master_output=0,\n",
    "        oracle_output=0\n",
    "    )\n",
    "\n",
    "    if best is None:\n",
    "        print(\"No WCE found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== BEST WCE FOUND ===\")\n",
    "    print(\"L1 dist:\", best[\"dist\"])\n",
    "    print(\"delta b:\", best[\"db\"])\n",
    "    print(\"new b:\", best[\"b\"])\n",
    "    print(\"theta:\", best[\"theta\"])\n",
    "    print(\"witness obj:\", best[\"witness\"][\"obj\"])\n",
    "    print(\"witness x:\", best[\"witness\"][\"x\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5) Sanity check\n",
    "    # -------------------------------\n",
    "    print(\"\\n=== RUN SANITY CHECK ===\")\n",
    "    sanity_check_wce_result(\n",
    "        base=base,\n",
    "        spec=spec,\n",
    "        desired_space_cb=desired_cb,\n",
    "        best=best,\n",
    "        tol=1e-6,\n",
    "        output_flag=0\n",
    "    )\n",
    "\n",
    "\n",
    "# ✅ ONLY THIS at top level\n",
    "demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eaffe7",
   "metadata": {},
   "source": [
    "# Mixed-Integer Weak-Optimality Counterfactual Explanations (WCE) via Projection / Value-Function Cuts (RHS-only)\n",
    "\n",
    "We consider a **lower-level MILP** (forward optimization) with continuous dispatch variables and binary commitment variables.  \n",
    "We want a **Weak-Optimality Counterfactual Explanation (WCE)**: the smallest change to selected parameters such that there exists **at least one lower-level optimal solution** that lies in a *desired space* (e.g., a generator must be ON).\n",
    "\n",
    "This notebook implements **Option 1**: only the **RHS** vector \\(b\\) is mutable (demand / limits), i.e.\n",
    "$$\n",
    "b(\\Delta) = b^0 + \\Delta b,\n",
    "$$\n",
    "with \\(\\Delta b\\) bounded and chosen to minimize an L1 distance.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Lower-level (forward) MILP\n",
    "\n",
    "Let the forward MILP be\n",
    "$$\n",
    "\\theta(\\Delta b) \\;=\\; \\min_{x,y} \\; c_x^\\top x + c_y^\\top y\n",
    "\\quad \\text{s.t.}\\quad\n",
    "A_x x + A_y y \\ge b^0 + \\Delta b,\\;\n",
    "x \\in X,\\; y \\in Y,\n",
    "$$\n",
    "where\n",
    "- $x$ are continuous variables (dispatch),\n",
    "- $y$ are integer/binary variables (commitments),\n",
    "- only RHS entries in $b$ are mutable.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Weak-optimality counterfactual explanation (WCE)\n",
    "\n",
    "Given a desired region $\\mathcal{D}$ (e.g. $u_1=1$), a **WCE** solves\n",
    "$$\n",
    "\\min_{\\Delta b} \\; \\|\\Delta b\\|_1\n",
    "\\quad \\text{s.t.}\\quad\n",
    "\\exists (x^w,y^w)\\in \\mathcal{D} \\cap \\arg\\min \\{c_x^\\top x + c_y^\\top y \\;:\\; A_x x + A_y y \\ge b^0 + \\Delta b\\}.\n",
    "$$\n",
    "“Weak optimality” means: **there exists at least one optimal solution** in $\\mathcal{D}$ (not necessarily all optimal solutions).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Value-function (projection) formulation for fixed integer pattern\n",
    "\n",
    "Fix an integer pattern $y\\in Y$. The remaining problem in $x$ is an LP:\n",
    "$$\n",
    "\\phi_y(\\Delta b) = c_y^\\top y + \\min_{x\\in X}\\{c_x^\\top x : A_x x \\ge (b^0+\\Delta b) - A_y y \\}.\n",
    "$$\n",
    "\n",
    "By LP strong duality (for fixed $y$), there exists a dual feasible polyhedron $\\Pi$ (independent of $\\Delta b$ when only RHS is mutable) such that\n",
    "$$\n",
    "\\phi_y(\\Delta b) \\;=\\; c_y^\\top y \\;+\\; \\max_{\\pi\\in \\Pi}\\; \\pi^\\top\\big((b^0+\\Delta b)-A_y y\\big).\n",
    "$$\n",
    "Therefore, the epigraph of $\\phi_y$ can be outer-approximated by **value-function cuts** (projection cuts):\n",
    "$$    \n",
    "\\eta_y \\;\\ge\\; c_y^\\top y + \\pi^\\top(b^0-A_y y) + \\pi^\\top \\Delta b,\n",
    "$$\n",
    "where $\\pi$ is a dual extreme point (or any dual optimal multiplier) for the fixed-$y$ LP.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Master problem (restricted)\n",
    "\n",
    "We introduce\n",
    "- witness variables $(x^w,y^w)$ that must satisfy feasibility and desired-space constraints,\n",
    "- a scalar $\\eta$ tied to the witness objective,\n",
    "- for each tracked competitor pattern $y$, a scalar $\\eta_y$ representing $\\phi_y(\\Delta b)$ via accumulated cuts.\n",
    "\n",
    "The master solves:\n",
    "- minimize $\\|\\Delta b\\|_1$,\n",
    "- enforce witness feasibility and desired constraints,\n",
    "- enforce $\\eta = c_x^\\top x^w + c_y^\\top y^w$,\n",
    "- enforce $\\eta \\le \\eta_y$ for tracked patterns $y$,\n",
    "- enforce value-function cuts for each tracked pattern.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Separation (oracle) and cut generation\n",
    "\n",
    "Given a master solution $\\Delta b$,\n",
    "1) Solve the full lower-level MILP to get the true optimum $\\theta(\\Delta b)$ and an optimal integer pattern $y^{sep}$.\n",
    "2) Check whether there exists an optimal solution in desired space (solve a witness-feasibility model with objective cap $\\le \\theta(\\Delta b)$).\n",
    "3) If WCE is not satisfied, generate a projection cut:\n",
    "   - Fix $y=y^{sep}$, solve the continuous LP in $x$,\n",
    "   - read dual multipliers $\\pi^\\star$ for the RHS constraints,\n",
    "   - add the cut\n",
    "     $$\n",
    "     \\eta_{y^{sep}} \\ge c_y^\\top y^{sep} + (\\pi^\\star)^\\top(b^0-A_y y^{sep}) + (\\pi^\\star)^\\top \\Delta b.\n",
    "     $$\n",
    "\n",
    "Repeat until WCE is found (or iteration limit is reached).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Why this is more rigorous than no-good cuts\n",
    "\n",
    "- No-good cuts eliminate **one** parameter vector $\\Delta b$ per iteration.\n",
    "- Projection/value-function cuts tighten a **convex, piecewise-linear** outer approximation of each $\\phi_y(\\Delta b)$, cutting off **regions** of $\\Delta b$.\n",
    "- For RHS-only mutability, the cuts are linear and theoretically grounded in LP duality and decomposition.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb5664a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional, Callable, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f74ac264",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class UCInstance:\n",
    "    \"\"\"\n",
    "    Small UC-like MILP:\n",
    "      - continuous generation g[i,t] >= 0\n",
    "      - binary commitment u[i] in {0,1} (shared across time for simplicity)\n",
    "      - demand constraints per period\n",
    "      - capacity constraints g[i,t] <= Pmax[i]*u[i]\n",
    "\n",
    "    We only allow RHS mutability on demand constraints: D_t = D0_t + db_t\n",
    "    \"\"\"\n",
    "    I: int\n",
    "    T: int\n",
    "    Pmax: np.ndarray          # (I,)\n",
    "    gen_cost: np.ndarray      # (I,) variable cost per MWh\n",
    "    fixed_cost: np.ndarray    # (I,) fixed cost for u_i\n",
    "    D0: np.ndarray            # (T,) base demand\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RHSOnlySpec:\n",
    "    \"\"\"\n",
    "    RHS-only mutable demand deltas.\n",
    "    db_t are integer deltas within [lb,ub] (finite => finite convergence on this grid).\n",
    "    \"\"\"\n",
    "    db_lb: int\n",
    "    db_ub: int\n",
    "    l1_weight: float = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e279db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_forward_uc(inst: UCInstance, D: np.ndarray, output_flag: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Solve full lower-level MILP for given demand vector D.\n",
    "    Returns objective, g, u, and the optimal u-pattern.\n",
    "    \"\"\"\n",
    "    m = gp.Model(\"uc_forward\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "\n",
    "    I, T = inst.I, inst.T\n",
    "    g = m.addVars(I, T, lb=0.0, vtype=GRB.CONTINUOUS, name=\"g\")\n",
    "    u = m.addVars(I, vtype=GRB.BINARY, name=\"u\")\n",
    "\n",
    "    # Objective\n",
    "    m.setObjective(\n",
    "        gp.quicksum(inst.gen_cost[i] * g[i,t] for i in range(I) for t in range(T))\n",
    "        + gp.quicksum(inst.fixed_cost[i] * u[i] for i in range(I)),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    # Demand constraints\n",
    "    demand_con = []\n",
    "    for t in range(T):\n",
    "        con = m.addConstr(gp.quicksum(g[i,t] for i in range(I)) >= float(D[t]), name=f\"demand[{t}]\")\n",
    "        demand_con.append(con)\n",
    "\n",
    "    # Capacity constraints\n",
    "    for i in range(I):\n",
    "        for t in range(T):\n",
    "            m.addConstr(g[i,t] <= float(inst.Pmax[i]) * u[i], name=f\"cap[{i},{t}]\")\n",
    "\n",
    "    m.optimize()\n",
    "    if m.Status != GRB.OPTIMAL:\n",
    "        return {\"status\": m.Status}\n",
    "\n",
    "    u_pat = tuple(int(round(u[i].X)) for i in range(I))\n",
    "    return {\n",
    "        \"status\": GRB.OPTIMAL,\n",
    "        \"obj\": float(m.ObjVal),\n",
    "        \"g\": np.array([[g[i,t].X for t in range(T)] for i in range(I)], dtype=float),\n",
    "        \"u\": np.array([int(round(u[i].X)) for i in range(I)], dtype=int),\n",
    "        \"u_pat\": u_pat\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63708a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_fixed_u_lp_get_cutdata(inst: UCInstance, D: np.ndarray, u_pat: Tuple[int, ...], output_flag: int = 0):\n",
    "    \"\"\"\n",
    "    Solve the fixed-u LP and return OA cut data:\n",
    "      Vu(Dk) and pi(Dk) where pi are dual multipliers of demand constraints.\n",
    "\n",
    "    OA/Benders cut:\n",
    "        eta_u >= Vu(Dk) + sum_t pi_t(Dk) * (D_t - Dk_t)\n",
    "\n",
    "    IMPORTANT:\n",
    "      - demand constraints must be written as sum g >= D  (exactly)\n",
    "      - we only use Pi of those demand constraints\n",
    "    \"\"\"\n",
    "    I, T = inst.I, inst.T\n",
    "\n",
    "    m = gp.Model(\"uc_fixed_u_lp\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "\n",
    "    g = m.addVars(I, T, lb=0.0, vtype=GRB.CONTINUOUS, name=\"g\")\n",
    "\n",
    "    fixed_term = gp.quicksum(float(inst.fixed_cost[i]) * int(u_pat[i]) for i in range(I))\n",
    "    var_term   = gp.quicksum(float(inst.gen_cost[i]) * g[i, t] for i in range(I) for t in range(T))\n",
    "    obj = var_term + fixed_term\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    # Demand constraints: sum_i g_it >= D_t\n",
    "    demand_con = []\n",
    "    for t in range(T):\n",
    "        con = m.addConstr(gp.quicksum(g[i, t] for i in range(I)) >= float(D[t]), name=f\"demand[{t}]\")\n",
    "        demand_con.append(con)\n",
    "\n",
    "    # Capacity constraints: g_it <= Pmax_i * u_i (fixed)\n",
    "    for i in range(I):\n",
    "        for t in range(T):\n",
    "            m.addConstr(g[i, t] <= float(inst.Pmax[i]) * int(u_pat[i]), name=f\"cap[{i},{t}]\")\n",
    "\n",
    "    m.optimize()\n",
    "    if m.Status != GRB.OPTIMAL:\n",
    "        return {\"status\": m.Status}\n",
    "\n",
    "    Vu = float(m.ObjVal)\n",
    "    pi = np.array([demand_con[t].Pi for t in range(T)], dtype=float)  # duals w.r.t. demand\n",
    "\n",
    "    return {\"status\": GRB.OPTIMAL, \"Vu\": Vu, \"pi\": pi, \"Dk\": np.array(D, dtype=float), \"u_pat\": u_pat}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "225327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def witness_exists_uc(\n",
    "    inst: UCInstance,\n",
    "    D: np.ndarray,\n",
    "    theta: float,\n",
    "    desired_cb: Callable[[gp.Model, Dict[Tuple[int,int], gp.Var], Dict[int, gp.Var]], None],\n",
    "    tol: float = 1e-6,\n",
    "    output_flag: int = 0\n",
    ") -> Tuple[bool, Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Check if exists an optimal solution in desired space:\n",
    "      feasible + desired constraints + objective <= theta + tol.\n",
    "    \"\"\"\n",
    "    m = gp.Model(\"uc_witness\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "\n",
    "    I, T = inst.I, inst.T\n",
    "    g = m.addVars(I, T, lb=0.0, vtype=GRB.CONTINUOUS, name=\"g\")\n",
    "    u = m.addVars(I, vtype=GRB.BINARY, name=\"u\")\n",
    "\n",
    "    obj = (\n",
    "        gp.quicksum(inst.gen_cost[i] * g[i,t] for i in range(I) for t in range(T))\n",
    "        + gp.quicksum(inst.fixed_cost[i] * u[i] for i in range(I))\n",
    "    )\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    # Demand constraints\n",
    "    for t in range(T):\n",
    "        m.addConstr(gp.quicksum(g[i,t] for i in range(I)) >= float(D[t]), name=f\"demand[{t}]\")\n",
    "\n",
    "    # Capacity constraints\n",
    "    for i in range(I):\n",
    "        for t in range(T):\n",
    "            m.addConstr(g[i,t] <= float(inst.Pmax[i]) * u[i], name=f\"cap[{i},{t}]\")\n",
    "\n",
    "    # Desired-space constraints\n",
    "    desired_cb(m, g, u)\n",
    "\n",
    "    # Weak optimality cap\n",
    "    m.addConstr(obj <= float(theta) + float(tol), name=\"opt_cap\")\n",
    "\n",
    "    m.optimize()\n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        return True, {\n",
    "            \"obj\": float(m.ObjVal),\n",
    "            \"u\": np.array([int(round(u[i].X)) for i in range(I)], dtype=int),\n",
    "            \"g\": np.array([[g[i,t].X for t in range(T)] for i in range(I)], dtype=float),\n",
    "        }\n",
    "    return False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00a8fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_master_uc_rhs_only(\n",
    "    inst: UCInstance,\n",
    "    spec: RHSOnlySpec,\n",
    "    desired_cb: Callable[[gp.Model, Any, Any], None],\n",
    "    tracked_patterns: List[Tuple[int, ...]],\n",
    "    cuts_by_pattern: Dict[Tuple[int, ...], List[Dict[str, Any]]],\n",
    "    output_flag: int = 0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Correct OA Master (RHS-only) for WCE.\n",
    "\n",
    "    Master variables:\n",
    "      - db[t] integer (demand shifts)\n",
    "      - witness vars g_w[i,t], u_w[i]\n",
    "      - eta[u_pat] (epigraph) for each tracked pattern\n",
    "\n",
    "    Constraints:\n",
    "      - witness feasibility at D = D0 + db\n",
    "      - desired constraints on witness\n",
    "      - witness_cost <= eta[u_pat] for all tracked u_pat\n",
    "      - eta[u_pat] >= OA cuts: Vu(Dk) + pi(Dk)^T (D - Dk)\n",
    "\n",
    "    Objective:\n",
    "      min sum |db[t]|\n",
    "    \"\"\"\n",
    "    I, T = inst.I, inst.T\n",
    "    m = gp.Model(\"master_uc_rhs_only\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "\n",
    "    # --------------------------\n",
    "    # db vars and L1 norm\n",
    "    # --------------------------\n",
    "    db = []\n",
    "    abs_terms = []\n",
    "    for t in range(T):\n",
    "        v = m.addVar(vtype=GRB.INTEGER, lb=spec.db_lb, ub=spec.db_ub, name=f\"db[{t}]\")\n",
    "        db.append(v)\n",
    "        p = m.addVar(lb=0.0, name=f\"abs_db_p[{t}]\")\n",
    "        n = m.addVar(lb=0.0, name=f\"abs_db_n[{t}]\")\n",
    "        m.addConstr(v == p - n, name=f\"abs_link[{t}]\")\n",
    "        abs_terms.append(p + n)\n",
    "\n",
    "    D_expr = [float(inst.D0[t]) + db[t] for t in range(T)]\n",
    "\n",
    "    # --------------------------\n",
    "    # Witness variables\n",
    "    # --------------------------\n",
    "    g_w = m.addVars(I, T, lb=0.0, vtype=GRB.CONTINUOUS, name=\"g_w\")\n",
    "    u_w = m.addVars(I, vtype=GRB.BINARY, name=\"u_w\")\n",
    "\n",
    "    # Witness feasibility\n",
    "    for t in range(T):\n",
    "        m.addConstr(gp.quicksum(g_w[i, t] for i in range(I)) >= D_expr[t], name=f\"w_demand[{t}]\")\n",
    "    for i in range(I):\n",
    "        for t in range(T):\n",
    "            m.addConstr(g_w[i, t] <= float(inst.Pmax[i]) * u_w[i], name=f\"w_cap[{i},{t}]\")\n",
    "\n",
    "    # Desired constraints\n",
    "    desired_cb(m, g_w, u_w)\n",
    "\n",
    "    # Witness cost\n",
    "    witness_cost = (\n",
    "        gp.quicksum(float(inst.gen_cost[i]) * g_w[i, t] for i in range(I) for t in range(T)) +\n",
    "        gp.quicksum(float(inst.fixed_cost[i]) * u_w[i] for i in range(I))\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # Epigraph variables eta[u] + OA cuts\n",
    "    # --------------------------\n",
    "    eta = {}\n",
    "    for u_pat in tracked_patterns:\n",
    "        key = \"\".join(map(str, u_pat))\n",
    "        eta_u = m.addVar(lb=-GRB.INFINITY, name=f\"eta[{key}]\")\n",
    "        eta[u_pat] = eta_u\n",
    "\n",
    "        # Witness must be no more expensive than value of each tracked competitor pattern\n",
    "        m.addConstr(witness_cost <= eta_u, name=f\"w_le_eta[{key}]\")\n",
    "\n",
    "        # OA cuts for this pattern\n",
    "        for k, cut in enumerate(cuts_by_pattern.get(u_pat, [])):\n",
    "            Vu_k = float(cut[\"Vu\"])\n",
    "            pi_k = np.array(cut[\"pi\"], dtype=float)\n",
    "            Dk   = np.array(cut[\"Dk\"], dtype=float)\n",
    "\n",
    "            rhs = Vu_k + gp.quicksum(float(pi_k[t]) * (D_expr[t] - float(Dk[t])) for t in range(T))\n",
    "            m.addConstr(eta_u >= rhs, name=f\"oa_cut[{key},{k}]\")\n",
    "\n",
    "        # IMPORTANT: if there are no cuts yet, eta is unbounded below and master becomes too weak.\n",
    "        # To prevent that, add a trivial lower bound cut at D0 if missing in caller logic.\n",
    "        if len(cuts_by_pattern.get(u_pat, [])) == 0:\n",
    "            # conservative: eta_u >= -1e9\n",
    "            m.addConstr(eta_u >= -1e9, name=f\"eta_lb_guard[{key}]\")\n",
    "\n",
    "    m.setObjective(float(spec.l1_weight) * gp.quicksum(abs_terms), GRB.MINIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    return {\"model\": m, \"db\": db, \"D_expr\": D_expr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ba04951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_oa_cut_validity(inst, u_pat, cut, D_test_list, output_flag=0, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Verifies that the OA cut:\n",
    "        eta >= Vu(Dk) + pi(Dk)^T (D - Dk)\n",
    "    is a LOWER bound on V_u(D) for multiple D points.\n",
    "\n",
    "    For each D_test:\n",
    "      compute V_u(D_test) by solving fixed-u LP\n",
    "      compute RHS of cut at D_test\n",
    "      assert V_u(D_test) >= RHS - eps\n",
    "    \"\"\"\n",
    "    Dk = cut[\"Dk\"]\n",
    "    Vu_k = cut[\"Vu\"]\n",
    "    pi_k = cut[\"pi\"]\n",
    "\n",
    "    for D in D_test_list:\n",
    "        lp = solve_fixed_u_lp_get_cutdata(inst, D, u_pat, output_flag=output_flag)\n",
    "        if lp[\"status\"] != GRB.OPTIMAL:\n",
    "            continue\n",
    "        Vu_D = lp[\"Vu\"]\n",
    "        rhs = Vu_k + float(np.dot(pi_k, (np.array(D, dtype=float) - np.array(Dk, dtype=float))))\n",
    "        if Vu_D + eps < rhs:\n",
    "            raise RuntimeError(\n",
    "                f\"OA cut INVALID for u={u_pat}\\n\"\n",
    "                f\"Dk={Dk}, Vu(Dk)={Vu_k}, pi={pi_k}\\n\"\n",
    "                f\"At D={D}: Vu(D)={Vu_D} < RHS={rhs}\\n\"\n",
    "                f\"This indicates the cut sign/sense is wrong (dual convention mismatch).\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2022ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wce_projection_oa_rhs_only_uc(\n",
    "    inst: UCInstance,\n",
    "    spec: RHSOnlySpec,\n",
    "    desired_cb: Callable[[gp.Model, Any, Any], None],\n",
    "    max_iter: int = 50,\n",
    "    tol: float = 1e-6,\n",
    "    master_output: int = 0,\n",
    "    oracle_output: int = 0\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    OA / projection algorithm for RHS-only WCE in the UC-like toy.\n",
    "\n",
    "    Key invariant:\n",
    "      tracked_patterns only contains patterns for which we have at least one valid OA cut.\n",
    "    \"\"\"\n",
    "    I, T = inst.I, inst.T\n",
    "\n",
    "    tracked_patterns: List[Tuple[int, ...]] = []\n",
    "    cuts_by_pattern: Dict[Tuple[int, ...], List[Dict[str, Any]]] = {}\n",
    "\n",
    "    # --------------------------\n",
    "    # Init at D0\n",
    "    # --------------------------\n",
    "    D0 = np.array(inst.D0, dtype=float)\n",
    "    fwd0 = solve_forward_uc(inst, D0, output_flag=oracle_output)\n",
    "    if fwd0.get(\"status\") != GRB.OPTIMAL:\n",
    "        return None\n",
    "\n",
    "    u0 = fwd0[\"u_pat\"]\n",
    "\n",
    "    # add pattern + first cut\n",
    "    cut0 = solve_fixed_u_lp_get_cutdata(inst, D0, u0, output_flag=oracle_output)\n",
    "    if cut0.get(\"status\") != GRB.OPTIMAL:\n",
    "        # If we cannot generate a cut, OA cannot proceed rigorously.\n",
    "        return None\n",
    "\n",
    "    tracked_patterns.append(u0)\n",
    "    cuts_by_pattern[u0] = [cut0]\n",
    "\n",
    "    # --------------------------\n",
    "    # OA loop\n",
    "    # --------------------------\n",
    "    for it in range(max_iter):\n",
    "        # 1) solve master\n",
    "        pack = build_master_uc_rhs_only(\n",
    "            inst=inst,\n",
    "            spec=spec,\n",
    "            desired_cb=desired_cb,\n",
    "            tracked_patterns=tracked_patterns,\n",
    "            cuts_by_pattern=cuts_by_pattern,\n",
    "            output_flag=master_output\n",
    "        )\n",
    "        m = pack[\"model\"]\n",
    "        m.optimize()\n",
    "        if m.Status != GRB.OPTIMAL:\n",
    "            return None\n",
    "\n",
    "        db_val = np.array([int(round(v.X)) for v in pack[\"db\"]], dtype=int)\n",
    "        D = np.array(inst.D0, dtype=float) + db_val\n",
    "        dist_l1 = float(m.ObjVal)\n",
    "\n",
    "        # 2) oracle: true forward solve at D\n",
    "        fwd = solve_forward_uc(inst, D, output_flag=oracle_output)\n",
    "        if fwd.get(\"status\") != GRB.OPTIMAL:\n",
    "            # shouldn’t happen often here, but skip if it does\n",
    "            continue\n",
    "\n",
    "        theta = float(fwd[\"obj\"])\n",
    "        u_hat = fwd[\"u_pat\"]\n",
    "\n",
    "        # 3) witness existence (weak optimality)\n",
    "        ok, wit = witness_exists_uc(inst, D, theta, desired_cb, tol=tol, output_flag=oracle_output)\n",
    "        if ok:\n",
    "            return {\n",
    "                \"iterations\": it + 1,\n",
    "                \"dist_l1\": dist_l1,\n",
    "                \"db\": db_val,\n",
    "                \"D\": D,\n",
    "                \"theta\": theta,\n",
    "                \"forward\": fwd,\n",
    "                \"witness\": wit,\n",
    "                \"tracked_patterns\": list(tracked_patterns),\n",
    "            }\n",
    "\n",
    "        # 4) add a cut for u_hat at this D\n",
    "        new_cut = solve_fixed_u_lp_get_cutdata(inst, D, u_hat, output_flag=oracle_output)\n",
    "        if new_cut.get(\"status\") != GRB.OPTIMAL:\n",
    "            # If fixed-u LP infeasible, then V_u(D)=+inf; that pattern is irrelevant at this D,\n",
    "            # but since u_hat came from a feasible forward MILP, fixed-u LP SHOULD be feasible.\n",
    "            # If it's not, there is a bug in fixed-u LP formulation.\n",
    "            continue\n",
    "\n",
    "        if u_hat not in cuts_by_pattern:\n",
    "            tracked_patterns.append(u_hat)\n",
    "            cuts_by_pattern[u_hat] = [new_cut]\n",
    "        else:\n",
    "            # avoid exact duplicates\n",
    "            duplicate = False\n",
    "            for old in cuts_by_pattern[u_hat]:\n",
    "                if np.max(np.abs(np.array(old[\"Dk\"]) - np.array(new_cut[\"Dk\"]))) <= 1e-12:\n",
    "                    duplicate = True\n",
    "                    break\n",
    "            if not duplicate:\n",
    "                cuts_by_pattern[u_hat].append(new_cut)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9901f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_scan_wce(inst, desired_cb, db_lb, db_ub, output_flag=0):\n",
    "    best = None\n",
    "    for d1 in range(db_lb, db_ub+1):\n",
    "        for d2 in range(db_lb, db_ub+1):\n",
    "            db = np.array([d1, d2], dtype=int)\n",
    "            D = inst.D0 + db\n",
    "            fw = solve_forward_uc(inst, D, output_flag=output_flag)\n",
    "            if fw.get(\"status\") != GRB.OPTIMAL:\n",
    "                continue\n",
    "            theta = fw[\"obj\"]\n",
    "            ok, wit = witness_exists_uc(inst, D, theta, desired_cb, tol=1e-6, output_flag=output_flag)\n",
    "            if ok:\n",
    "                dist = abs(d1) + abs(d2)\n",
    "                if (best is None) or (dist < best[\"dist\"]):\n",
    "                    best = {\"db\": db, \"D\": D, \"dist\": dist, \"theta\": theta, \"wit\": wit, \"fw\": fw}\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "324a771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_best_uc(inst: UCInstance, desired_cb, best: Dict[str, Any], tol: float = 1e-6, output_flag: int = 0):\n",
    "    if best is None:\n",
    "        raise ValueError(\"best is None\")\n",
    "\n",
    "    D = best[\"D\"]\n",
    "    # recompute forward\n",
    "    fw = solve_forward_uc(inst, D, output_flag=output_flag)\n",
    "    if fw.get(\"status\") != GRB.OPTIMAL:\n",
    "        raise RuntimeError(\"Sanity: forward not optimal\")\n",
    "\n",
    "    theta = fw[\"obj\"]\n",
    "    # witness existence at theta\n",
    "    ok, _ = witness_exists_uc(inst, D, theta, desired_cb, tol=tol, output_flag=output_flag)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"Sanity: witness does not exist at recomputed theta\")\n",
    "\n",
    "    print(\"Sanity check passed.\")\n",
    "    print(f\"theta={theta:.6f}, stored theta={best['theta']:.6f}, gap={best['theta']-theta:+.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86c6f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BRUTE SCAN (existence check) ===\n",
      "Found WCE by brute force:\n",
      "dist: 1 db: [0 1] D: [6. 7.]\n",
      "forward u: [1 1 1] theta: 30.1\n",
      "witness u: [1 1 1] witness obj: 30.1\n",
      "best from OA: None\n",
      "No WCE found (OA failed) — usually indicates cut implementation is incorrect.\n"
     ]
    }
   ],
   "source": [
    "def demo():\n",
    "    # -------------------------------\n",
    "    # 1) Define the base MILP (UC-like)\n",
    "    # -------------------------------\n",
    "    I, T = 3, 2\n",
    "    Pmax = np.array([6.0, 6.0, 6.0])\n",
    "\n",
    "    gen_cost = np.array([2.0, 2.1, 6.0])\n",
    "    fixed_cost = np.array([3.0, 1.0, 0.0])\n",
    "\n",
    "    D0 = np.array([6.0, 6.0])\n",
    "    base = UCInstance(I=I, T=T, Pmax=Pmax, gen_cost=gen_cost, fixed_cost=fixed_cost, D0=D0)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) Desired space\n",
    "    # -------------------------------\n",
    "    def desired_cb(model, gvars, uvars):\n",
    "        model.addConstr(uvars[0] == 1, name=\"desired_u1_on\")\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) Mutable specification (RHS-only)\n",
    "    # -------------------------------\n",
    "    spec = RHSOnlySpec(\n",
    "        db_lb=-10,\n",
    "        db_ub=10,\n",
    "        l1_weight=1.0\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3.5) Brute existence sanity scan\n",
    "    # -------------------------------\n",
    "    brute = brute_scan_wce(base, desired_cb, db_lb=-10, db_ub=10, output_flag=0)\n",
    "    print(\"\\n=== BRUTE SCAN (existence check) ===\")\n",
    "    if brute is None:\n",
    "        print(\"No WCE exists within the db bounds (so OA cannot find one).\")\n",
    "        return\n",
    "    print(\"Found WCE by brute force:\")\n",
    "    print(\"dist:\", brute[\"dist\"], \"db:\", brute[\"db\"], \"D:\", brute[\"D\"])\n",
    "    print(\"forward u:\", brute[\"fw\"][\"u\"], \"theta:\", brute[\"theta\"])\n",
    "    print(\"witness u:\", brute[\"wit\"][\"u\"], \"witness obj:\", brute[\"wit\"][\"obj\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4) Solve WCE (Projection / OA)\n",
    "    # -------------------------------\n",
    "    best = wce_projection_oa_rhs_only_uc(\n",
    "        inst=base,\n",
    "        spec=spec,\n",
    "        desired_cb=desired_cb,\n",
    "        max_iter=50,\n",
    "        tol=1e-6,\n",
    "        master_output=0,\n",
    "        oracle_output=0\n",
    "    )\n",
    "    print(\"best from OA:\", best)\n",
    "    if best is None:\n",
    "        print(\"No WCE found (OA failed) — usually indicates cut implementation is incorrect.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n=== BEST WCE FOUND (OA) ===\")\n",
    "    print(\"iterations:\", best[\"iterations\"])\n",
    "    print(\"L1 dist:\", best[\"dist_l1\"])\n",
    "    print(\"db:\", best[\"db\"], \"=> D:\", best[\"D\"])\n",
    "    print(\"theta:\", best[\"theta\"])\n",
    "    print(\"forward u:\", best[\"forward\"][\"u\"], \"pattern:\", best[\"forward\"][\"u_pat\"])\n",
    "    print(\"witness u:\", best[\"witness\"][\"u\"])\n",
    "    print(\"witness obj:\", best[\"witness\"][\"obj\"])\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5) Sanity check\n",
    "    # -------------------------------\n",
    "    print(\"\\n=== RUN SANITY CHECK ===\")\n",
    "    sanity_check_best_uc(base, desired_cb, best, tol=1e-6, output_flag=0)\n",
    "\n",
    "\n",
    "# ✅ ONLY THIS at top level\n",
    "demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99262328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Academic license 2653481 - for non-commercial use only - registered to to___@ug.uchile.cl\n",
      "Optimize a model with 8 rows, 9 columns and 18 nonzeros (Min)\n",
      "Model fingerprint: 0xd684668a\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 6 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+00]\n",
      "  Objective range  [1e+00, 6e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e+00, 7e+00]\n",
      "Presolve removed 2 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 6 rows, 8 columns, 14 nonzeros\n",
      "Variable types: 0 continuous, 8 integer (2 binary)\n",
      "Found heuristic solution: objective 30.1000000\n",
      "\n",
      "Root relaxation: objective 2.860000e+01, 5 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   28.60000    0    1   30.10000   28.60000  4.98%     -    0s\n",
      "\n",
      "Explored 1 nodes (5 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 30.1 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.010000000000e+01, best bound 3.010000000000e+01, gap 0.0000%\n",
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Academic license 2653481 - for non-commercial use only - registered to to___@ug.uchile.cl\n",
      "Optimize a model with 10 rows, 9 columns and 27 nonzeros (Min)\n",
      "Model fingerprint: 0x0c54d10e\n",
      "Model has 8 linear objective coefficients\n",
      "Variable types: 6 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+00]\n",
      "  Objective range  [1e+00, 6e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+01]\n",
      "Presolve removed 8 rows and 6 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 2 rows, 3 columns, 6 nonzeros\n",
      "Variable types: 3 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 3.010000e+01, 0 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0      30.1000000   30.10000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 30.1 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.010000000000e+01, best bound 3.010000000000e+01, gap 0.0000%\n",
      "Witness exists? True\n",
      "Witness obj: 30.1\n",
      "Witness u: [1 1 1]\n",
      "FW status: 2\n",
      "FW obj: 30.1\n",
      "FW u: [1 1 1] u_pat: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "D_test = np.array([6.0, 7.0])\n",
    "I, T = 3, 2\n",
    "Pmax = np.array([6.0, 6.0, 6.0])\n",
    "\n",
    "gen_cost = np.array([2.0, 2.1, 6.0])\n",
    "fixed_cost = np.array([3.0, 1.0, 0.0])\n",
    "\n",
    "D0 = np.array([6.0, 7.0])\n",
    "base = UCInstance(I=I, T=T, Pmax=Pmax, gen_cost=gen_cost, fixed_cost=fixed_cost, D0=D0)\n",
    "def desired_cb(model, gvars, uvars):\n",
    "    model.addConstr(uvars[0] == 1, name=\"desired_u1_on\")\n",
    "\n",
    "fw = solve_forward_uc(base, D_test, output_flag=1)\n",
    "\n",
    "\n",
    "\n",
    "theta = fw[\"obj\"]\n",
    "ok, wit = witness_exists_uc(base, D_test, theta, desired_cb, tol=1e-6, output_flag=1)\n",
    "\n",
    "print(\"Witness exists?\", ok)\n",
    "if ok:\n",
    "    print(\"Witness obj:\", wit[\"obj\"])\n",
    "    print(\"Witness u:\", wit[\"u\"])\n",
    "\n",
    "print(\"FW status:\", fw[\"status\"])\n",
    "print(\"FW obj:\", fw[\"obj\"])\n",
    "print(\"FW u:\", fw[\"u\"], \"u_pat:\", fw[\"u_pat\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9000979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patterns: [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "all_patterns = [tuple(p) for p in product([0,1],[0,1],[0,1])]\n",
    "print(\"patterns:\", all_patterns)\n",
    "spec = RHSOnlySpec(db_lb=-10, db_ub=10, l1_weight=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3233a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Academic license 2653481 - for non-commercial use only - registered to to___@ug.uchile.cl\n",
      "Optimize a model with 13 rows, 16 columns and 39 nonzeros (Min)\n",
      "Model fingerprint: 0x44f9727f\n",
      "Model has 4 linear objective coefficients\n",
      "Variable types: 11 continuous, 5 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+01]\n",
      "  RHS range        [1e+00, 3e+01]\n",
      "Presolve removed 13 rows and 16 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "{'iterations': 1, 'dist_l1': 0.0, 'db': array([0, 0]), 'D': array([6., 7.]), 'theta': 30.1, 'forward': {'status': 2, 'obj': 30.1, 'g': array([[6., 6.],\n",
      "       [0., 1.],\n",
      "       [0., 0.]]), 'u': array([1, 1, 1]), 'u_pat': (1, 1, 1)}, 'witness': {'obj': 30.1, 'u': array([1, 1, 1]), 'g': array([[6., 6.],\n",
      "       [0., 1.],\n",
      "       [0., 0.]])}, 'tracked_patterns': [(1, 1, 1)]}\n"
     ]
    }
   ],
   "source": [
    "best = wce_projection_oa_rhs_only_uc(\n",
    "    inst=base,\n",
    "    spec=spec,\n",
    "    desired_cb=desired_cb,\n",
    "    max_iter=50,\n",
    "    tol=1e-6,\n",
    "    master_output=1,\n",
    "    oracle_output=0\n",
    ")\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
